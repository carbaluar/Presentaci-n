{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba LB",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "197raptSaIHCh4CJCDM929P0in5fOSOQK",
      "authorship_tag": "ABX9TyPwmFMgvUeGZjGkP+hMRro2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carbaluar/Presentaci-n/blob/main/Prueba_LB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cemm7EHNji8f"
      },
      "source": [
        "## Generamos el Archivo de Excel para la lectura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ZeWuTWmaB4"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import sqlite3\n",
        "import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "Z7y-pSf8jnOI",
        "outputId": "25afd2c5-9319-4ace-8018-88775c4219a1"
      },
      "source": [
        "\n",
        "dfAL = pd.read_excel('/content/DBdiario_2.xlsx',sheet_name='diario B')\n",
        "dfAL.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dia</th>\n",
              "      <th>dens B</th>\n",
              "      <th>coque</th>\n",
              "      <th>restos</th>\n",
              "      <th>pot B</th>\n",
              "      <th>RdensB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1.430199</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.29</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>1.428183</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.27</td>\n",
              "      <td>7.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>1.432999</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.38</td>\n",
              "      <td>7.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-06</td>\n",
              "      <td>1.431003</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.31</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-07</td>\n",
              "      <td>1.436301</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.32</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         dia    dens B  coque  restos  pot B  RdensB\n",
              "0 2018-01-01  1.430199   0.86    0.29    7.7       1\n",
              "1 2018-01-02  1.428183   0.86    0.27    7.8       1\n",
              "2 2018-01-05  1.432999   0.86    0.38    7.8       1\n",
              "3 2018-01-06  1.431003   0.86    0.31    7.7       1\n",
              "4 2018-01-07  1.436301   0.86    0.32    7.7       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-4S3bIuwrwN",
        "outputId": "a5456e33-ddd5-471b-e695-a9954ba2dbd2"
      },
      "source": [
        "dfAL.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 758 entries, 0 to 757\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   dia     758 non-null    datetime64[ns]\n",
            " 1   dens B  758 non-null    float64       \n",
            " 2   coque   758 non-null    float64       \n",
            " 3   restos  758 non-null    float64       \n",
            " 4   pot B   758 non-null    float64       \n",
            " 5   RdensB  758 non-null    int64         \n",
            "dtypes: datetime64[ns](1), float64(4), int64(1)\n",
            "memory usage: 35.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCXH9AwXmkIn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hmkmQCTp47Z"
      },
      "source": [
        "# divido entre train y test/validación en 70%/30%\n",
        "dfAL_train, dfAL_test_validation = train_test_split(dfAL, train_size=0.7, stratify = dfAL[\"RdensB\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP4KTUXSq7F7"
      },
      "source": [
        "# divido entre train y test/validación en 15% y 15%\n",
        "dfAL_test, dfAL_validation = train_test_split(dfAL_test_validation, train_size=0.5, stratify = dfAL_test_validation[\"RdensB\"])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUdZsA3ZtHZh",
        "outputId": "57751185-f27a-4a08-be10-e7d2fc18199c"
      },
      "source": [
        "dfAL_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(530, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S756st1stL4g",
        "outputId": "0475411c-c8c6-48d1-d18d-ed45b6321cdd"
      },
      "source": [
        "dfAL_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7_CuF_6tTaN",
        "outputId": "a37ac1ec-2969-42bb-9e50-645c8c45055b"
      },
      "source": [
        "dfAL_validation.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycFpnHvC-u4L"
      },
      "source": [
        "### Modelo Gaussiano"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upJiH-MItXVo"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wYXULIItkga"
      },
      "source": [
        "clf = GaussianNB(priors=None, var_smoothing= 0.001)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_F1k8rCt4X_"
      },
      "source": [
        "dfAL_train2 = dfAL_train[[\"pot B\",\"coque\",\"restos\",\"RdensB\"]].copy()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOd820hbu3gh",
        "outputId": "481f0726-9d2b-4fb8-f6f1-ad652d05b59c"
      },
      "source": [
        "clf.fit(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbutu0yCvF_l",
        "outputId": "d2157acf-2cf5-4ef6-eb39-1a6fc6105bb2"
      },
      "source": [
        "clf.score(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8830188679245283"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbrC7RgZv9GW"
      },
      "source": [
        "dfAL_validation2 = dfAL_validation[[\"pot B\",\"coque\",\"restos\",\"RdensB\"]].copy()\n",
        "dfAL_test_validation2 = dfAL_test_validation[[\"pot B\",\"coque\",\"restos\",\"RdensB\"]].copy()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EEvVjOHwDLZ",
        "outputId": "21534d9f-9966-4a18-a4a8-282d19904e54"
      },
      "source": [
        "clf.score(dfAL_validation2.drop(\"RdensB\",axis=1), dfAL_validation2[\"RdensB\"])\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8859649122807017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whumwuztFYCy",
        "outputId": "a2b1ed8c-be63-4954-d726-a34ca063dfd4"
      },
      "source": [
        "clf.score(dfAL_test_validation2.drop(\"RdensB\",axis=1), dfAL_test_validation2[\"RdensB\"])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8947368421052632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHJiQhyiwNFd"
      },
      "source": [
        "BuscaSmoot = [0.1, 0.001, 0.0001, 0.00001, 0.000001, 0.000000000001]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3MYNSY8yn3z",
        "outputId": "dbd38e06-847e-4265-9283-582e120a4a68"
      },
      "source": [
        "scores = list()\n",
        "for busca in BuscaSmoot:\n",
        "    clf = GaussianNB(var_smoothing = busca)\n",
        "    clf.fit(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])\n",
        "    scores.append(clf.score(dfAL_validation2.drop(\"RdensB\",axis=1), dfAL_validation2[\"RdensB\"]))\n",
        "\n",
        "print(\"Máximo score con un smoothing de: \", BuscaSmoot[scores.index(max(scores))], \"--> valor de Score: \", max(scores))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Máximo score con un smoothing de:  0.1 --> valor de Score:  0.8859649122807017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8nHpoYZFfCa",
        "outputId": "80005dcc-5f6e-4a39-8902-3e3764c910fa"
      },
      "source": [
        "scores = list()\n",
        "for busca in BuscaSmoot:\n",
        "    clf = GaussianNB(var_smoothing = busca)\n",
        "    clf.fit(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])\n",
        "    scores.append(clf.score(dfAL_test_validation2.drop(\"RdensB\",axis=1), dfAL_test_validation2[\"RdensB\"]))\n",
        "\n",
        "print(\"Máximo score con un smoothing de: \", BuscaSmoot[scores.index(max(scores))], \"--> valor de Score: \", max(scores))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Máximo score con un smoothing de:  0.001 --> valor de Score:  0.8947368421052632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ertKUX--zoj"
      },
      "source": [
        "Dato Obtenido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "IE5lH6kb-_PX",
        "outputId": "df3543b8-18ad-4bdb-d1fb-b2149a183e9a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "dfAL_train2.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pot B</th>\n",
              "      <th>coque</th>\n",
              "      <th>restos</th>\n",
              "      <th>RdensB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pot B  coque  restos  RdensB\n",
              "664    7.5   0.83    0.27       1\n",
              "388    7.5   0.84    0.30       1\n",
              "385    7.6   0.84    0.30       1\n",
              "196    7.9   0.82    0.30       1\n",
              "279    7.6   0.83    0.29       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juIxOtWr_Rnp",
        "outputId": "8fd5da67-e8fe-44e3-c79e-e0a906adbab3"
      },
      "source": [
        "clf.predict(np.array([[8,0.85,0.3]]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrcyJwKEC38-"
      },
      "source": [
        "Matriz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8iyTRBIC5xk"
      },
      "source": [
        "y_true = 1*np.array(dfAL_validation2[\"RdensB\"])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVwZW5lmFvfT"
      },
      "source": [
        "y_true2 = 1*np.array(dfAL_test_validation2[\"RdensB\"])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkE3o2HsDgpi"
      },
      "source": [
        "y_pred = clf.predict_proba(dfAL_validation2.drop(\"RdensB\",axis=1))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQkbaVazF1Qz"
      },
      "source": [
        "y_pred2 = clf.predict_proba(dfAL_test_validation2.drop(\"RdensB\",axis=1))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akt8DwPEDr4-",
        "outputId": "4f5cd8ce-3d24-4b80-c20b-605c05457c7b"
      },
      "source": [
        "print(\"Matriz de Confusión Alfa 0.25\")\n",
        "print(confusion_matrix(y_true,y_pred[:,1]>0.25))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz de Confusión Alfa 0.25\n",
            "[[  1  12]\n",
            " [  1 100]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMxjmqMNF81X",
        "outputId": "c0fafd10-d9ea-400b-c6bf-270b53bf3963"
      },
      "source": [
        "print(\"Matriz de Confusión Alfa 0.25\")\n",
        "print(confusion_matrix(y_true2,y_pred2[:,1]>0.25))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz de Confusión Alfa 0.25\n",
            "[[  1  25]\n",
            " [  1 201]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAihpKoIEF7d",
        "outputId": "8e7ee38c-f76c-4e0a-8fc2-4fa2b7fb65d2"
      },
      "source": [
        "alfa = 0.02\n",
        "recalls = np.zeros(100)\n",
        "precisions= np.zeros(100)\n",
        "FPR = np.zeros(100)\n",
        "alfas = np.linspace(0,1,100)\n",
        "for idx,alfa in enumerate(alfas):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred[:,1]>alfa).ravel()\n",
        "    recalls[idx] = (tp/(tp+fn))\n",
        "    precisions[idx] = (tp/(tp+fp))\n",
        "    FPR[idx]= (fp/(fp+tn))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY1WmUCcGQiI",
        "outputId": "379fe107-0054-40dc-9f05-e547fe38e0fd"
      },
      "source": [
        "alfa = 0.02\n",
        "recalls = np.zeros(100)\n",
        "precisions= np.zeros(100)\n",
        "FPR = np.zeros(100)\n",
        "alfas = np.linspace(0,1,100)\n",
        "for idx,alfa in enumerate(alfas):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true2,y_pred2[:,1]>alfa).ravel()\n",
        "    recalls[idx] = (tp/(tp+fn))\n",
        "    precisions[idx] = (tp/(tp+fp))\n",
        "    FPR[idx]= (fp/(fp+tn))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP_jb-1aETr7",
        "outputId": "2ca13aaa-c450-4916-e94a-9482e6a2d24f"
      },
      "source": [
        "print(\"Para un alfa 0.25 --> Valor de recall\", recalls[25], \"Valor de Precisions\", precisions[25], \"Valor de FPR\", FPR[25])\n",
        "print(\"Para un alfa 0.5 --> Valor de recall\", recalls[50], \"Valor de Precisions\", precisions[50], \"Valor de FPR\", FPR[50])\n",
        "print(\"Para un alfa 0.75 --> Valor de recall\", recalls[75], \"Valor de Precisions\", precisions[75], \"Valor de FPR\", FPR[75])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para un alfa 0.25 --> Valor de recall 0.9900990099009901 Valor de Precisions 0.8928571428571429 Valor de FPR 0.9230769230769231\n",
            "Para un alfa 0.5 --> Valor de recall 0.9801980198019802 Valor de Precisions 0.9 Valor de FPR 0.8461538461538461\n",
            "Para un alfa 0.75 --> Valor de recall 0.9108910891089109 Valor de Precisions 0.9108910891089109 Valor de FPR 0.6923076923076923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIHsn2pkGacm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "5b6st8OmEk0y",
        "outputId": "5128bb2b-4b78-4cba-e420-3674fb2b0ddc"
      },
      "source": [
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(FPR,recalls)\n",
        "plt.title(\"Curva ROC ejercicio densidad Línea B\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1JcaxfLzLrr"
      },
      "source": [
        "Modelo LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfnIGwO1zPa6"
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyJxoraQ0xw"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bNbY4E_zSfE"
      },
      "source": [
        "LDA_clf = LinearDiscriminantAnalysis()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e11vd0fzVJy",
        "outputId": "f0cc50a9-588a-43c2-ec2f-8f5efdaf638e"
      },
      "source": [
        "LDA_clf.fit(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
              "                           solver='svd', store_covariance=False, tol=0.0001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHpahvdWzht5",
        "outputId": "4ab429f4-cd61-4c36-8e68-bb16ed2687e2"
      },
      "source": [
        "LDA_clf.score(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8905660377358491"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcQV1Wj-zypM",
        "outputId": "7d56fbd9-206d-47b1-f736-1771fe11c53b"
      },
      "source": [
        "LDA_clf.score(dfAL_validation2.drop(\"RdensB\",axis=1), dfAL_validation2[\"RdensB\"])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8859649122807017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTic4LU6Q-GB",
        "outputId": "dd5ee4c2-b556-41b5-9055-01845c62c978"
      },
      "source": [
        "LDA_clf.predict(np.array([[7,0.86,0.25]]))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7taMRq66HEA-"
      },
      "source": [
        "y_true2 = 1*np.array(dfAL_test_validation2[\"RdensB\"])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xICYjYXvHIKq"
      },
      "source": [
        "y_pred_LDA = LDA_clf.predict_proba(dfAL_test_validation2.drop(\"RdensB\",axis=1))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJWYG2d6G921",
        "outputId": "c508c2af-0f1f-422f-a6f6-95cc4089a39c"
      },
      "source": [
        "print(\"Matriz de Confusión Alfa 0.25\")\n",
        "print(confusion_matrix(y_true2,y_pred_LDA[:,1]>0.25))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz de Confusión Alfa 0.25\n",
            "[[  0  26]\n",
            " [  1 201]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYC7sjTNz7bI"
      },
      "source": [
        "Modelo QDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQQd8QZFz6ot"
      },
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "QDA_clf = QuadraticDiscriminantAnalysis()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot9T55nIR1Ij"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1DS6E7oz6r3",
        "outputId": "a0148495-f046-42a5-ef42-ba3489a84efe"
      },
      "source": [
        "QDA_clf.fit(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
              "                              store_covariance=False, tol=0.0001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEWszqu00Tac",
        "outputId": "76e489f1-1f9c-4045-c8c9-acb0883bd86a"
      },
      "source": [
        "QDA_clf.score(dfAL_train2.drop(\"RdensB\",axis=1), dfAL_train2[\"RdensB\"])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHfHK7Y40XLa",
        "outputId": "3ab1fdf6-165b-4194-feb2-29536f97d0ae"
      },
      "source": [
        "QDA_clf.score(dfAL_validation2.drop(\"RdensB\",axis=1), dfAL_validation2[\"RdensB\"])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mYK-grKSJDF",
        "outputId": "da13737c-4a35-4b47-93e6-fd4dde4aff67"
      },
      "source": [
        "QDA_clf.predict(np.array([[5,0.86,0.25]]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Roicehdx0joA"
      },
      "source": [
        "Modelo de Regresión Log."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmfG_vOT0owp"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR_clf=LogisticRegression(C=1e9, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOmY92-e0p4Z",
        "outputId": "bf9da8ee-c707-4c05-cf22-dfdca60449eb"
      },
      "source": [
        "LR_clf.fit(dfAL_train2.drop(\"RdensA\",axis=1), dfAL_train2[\"RdensA\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=1,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHCTrzUB0vtR",
        "outputId": "d5a86406-a676-4f13-9666-a9dab6530b1c"
      },
      "source": [
        "LR_clf.score(dfAL_train2.drop(\"RdensA\",axis=1), dfAL_train2[\"RdensA\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7161961367013373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAQHtj4t05dC",
        "outputId": "db64cc47-2a31-42f8-b289-54a44b8c06a7"
      },
      "source": [
        "LR_clf.score(dfAL_validation2.drop(\"RdensA\",axis=1), dfAL_validation2[\"RdensA\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7172413793103448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4JAGTnp1MqB"
      },
      "source": [
        "Modelo de Redes Neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Yfhf7_23jA",
        "outputId": "2101cdc4-6d09-414a-a748-3f9c1ab794a4"
      },
      "source": [
        "dfAL_train2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(673, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixGihCZ1QIR"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGBuC5Wq1STp"
      },
      "source": [
        "RN_clf= Sequential()\n",
        "RN_clf.add(BatchNormalization(input_shape=(3,)))\n",
        "RN_clf.add(Dense(16, input_dim=5, activation='relu'))\n",
        "RN_clf.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ljWc0dI17mx"
      },
      "source": [
        "RN_clf.compile(loss='mean_squared_error',\n",
        "              optimizer='SGD',\n",
        "              metrics=['binary_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5tLnAxG2E-Q",
        "outputId": "db4525b4-7b45-4d7b-dd46-7c196c2dd6a8"
      },
      "source": [
        "RN_clf.fit(dfAL_train2.drop(\"RdensA\",axis=1), dfAL_train2[\"RdensA\"], epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1938 - binary_accuracy: 0.7132\n",
            "Epoch 2/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1935 - binary_accuracy: 0.7088\n",
            "Epoch 3/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1938 - binary_accuracy: 0.7177\n",
            "Epoch 4/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.7132\n",
            "Epoch 5/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1938 - binary_accuracy: 0.7073\n",
            "Epoch 6/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1935 - binary_accuracy: 0.7088\n",
            "Epoch 7/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1941 - binary_accuracy: 0.7058\n",
            "Epoch 8/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1939 - binary_accuracy: 0.7117\n",
            "Epoch 9/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1931 - binary_accuracy: 0.7132\n",
            "Epoch 10/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1933 - binary_accuracy: 0.7088\n",
            "Epoch 11/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1952 - binary_accuracy: 0.7103\n",
            "Epoch 12/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1928 - binary_accuracy: 0.7147\n",
            "Epoch 13/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1938 - binary_accuracy: 0.7073\n",
            "Epoch 14/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1933 - binary_accuracy: 0.7088\n",
            "Epoch 15/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1933 - binary_accuracy: 0.7147\n",
            "Epoch 16/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1927 - binary_accuracy: 0.7117\n",
            "Epoch 17/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1922 - binary_accuracy: 0.7177\n",
            "Epoch 18/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1933 - binary_accuracy: 0.7103\n",
            "Epoch 19/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1936 - binary_accuracy: 0.7147\n",
            "Epoch 20/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1935 - binary_accuracy: 0.7132\n",
            "Epoch 21/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1948 - binary_accuracy: 0.7103\n",
            "Epoch 22/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1936 - binary_accuracy: 0.7088\n",
            "Epoch 23/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1928 - binary_accuracy: 0.7147\n",
            "Epoch 24/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1929 - binary_accuracy: 0.7162\n",
            "Epoch 25/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1920 - binary_accuracy: 0.7147\n",
            "Epoch 26/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1934 - binary_accuracy: 0.7043\n",
            "Epoch 27/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7147\n",
            "Epoch 28/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1926 - binary_accuracy: 0.7147\n",
            "Epoch 29/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.7103\n",
            "Epoch 30/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 0.7177\n",
            "Epoch 31/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7177\n",
            "Epoch 32/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7073\n",
            "Epoch 33/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1922 - binary_accuracy: 0.7103\n",
            "Epoch 34/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1930 - binary_accuracy: 0.7117\n",
            "Epoch 35/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.7132\n",
            "Epoch 36/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1934 - binary_accuracy: 0.7058\n",
            "Epoch 37/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.7147\n",
            "Epoch 38/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1929 - binary_accuracy: 0.7088\n",
            "Epoch 39/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7088\n",
            "Epoch 40/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1929 - binary_accuracy: 0.7117\n",
            "Epoch 41/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1913 - binary_accuracy: 0.7117\n",
            "Epoch 42/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1910 - binary_accuracy: 0.7192\n",
            "Epoch 43/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1941 - binary_accuracy: 0.7117\n",
            "Epoch 44/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 0.7132\n",
            "Epoch 45/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1926 - binary_accuracy: 0.7162\n",
            "Epoch 46/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7103\n",
            "Epoch 47/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1914 - binary_accuracy: 0.7103\n",
            "Epoch 48/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1919 - binary_accuracy: 0.7103\n",
            "Epoch 49/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1930 - binary_accuracy: 0.7117\n",
            "Epoch 50/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1927 - binary_accuracy: 0.7147\n",
            "Epoch 51/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 0.7103\n",
            "Epoch 52/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7147\n",
            "Epoch 53/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7132\n",
            "Epoch 54/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1930 - binary_accuracy: 0.7117\n",
            "Epoch 55/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1911 - binary_accuracy: 0.7147\n",
            "Epoch 56/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7147\n",
            "Epoch 57/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1928 - binary_accuracy: 0.7162\n",
            "Epoch 58/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7117\n",
            "Epoch 59/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7177\n",
            "Epoch 60/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7207\n",
            "Epoch 61/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 0.7177\n",
            "Epoch 62/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7177\n",
            "Epoch 63/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7221\n",
            "Epoch 64/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1913 - binary_accuracy: 0.7162\n",
            "Epoch 65/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7177\n",
            "Epoch 66/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1912 - binary_accuracy: 0.7177\n",
            "Epoch 67/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7177\n",
            "Epoch 68/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7266\n",
            "Epoch 69/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1919 - binary_accuracy: 0.7058\n",
            "Epoch 70/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7088\n",
            "Epoch 71/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1912 - binary_accuracy: 0.7147\n",
            "Epoch 72/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7117\n",
            "Epoch 73/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.7117\n",
            "Epoch 74/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1911 - binary_accuracy: 0.7117\n",
            "Epoch 75/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.7147\n",
            "Epoch 76/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1926 - binary_accuracy: 0.7147\n",
            "Epoch 77/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 0.7132\n",
            "Epoch 78/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7162\n",
            "Epoch 79/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.7132\n",
            "Epoch 80/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1918 - binary_accuracy: 0.7162\n",
            "Epoch 81/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 0.7147\n",
            "Epoch 82/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7147\n",
            "Epoch 83/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7221\n",
            "Epoch 84/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1914 - binary_accuracy: 0.7132\n",
            "Epoch 85/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.7162\n",
            "Epoch 86/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7147\n",
            "Epoch 87/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7132\n",
            "Epoch 88/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1927 - binary_accuracy: 0.7103\n",
            "Epoch 89/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 0.7221\n",
            "Epoch 90/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1919 - binary_accuracy: 0.7058\n",
            "Epoch 91/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1913 - binary_accuracy: 0.7117\n",
            "Epoch 92/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7058\n",
            "Epoch 93/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 0.7177\n",
            "Epoch 94/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7207\n",
            "Epoch 95/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7192\n",
            "Epoch 96/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1904 - binary_accuracy: 0.7207\n",
            "Epoch 97/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7147\n",
            "Epoch 98/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7147\n",
            "Epoch 99/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7236\n",
            "Epoch 100/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.7192\n",
            "Epoch 101/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7207\n",
            "Epoch 102/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7162\n",
            "Epoch 103/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7132\n",
            "Epoch 104/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1912 - binary_accuracy: 0.7147\n",
            "Epoch 105/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7132\n",
            "Epoch 106/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7177\n",
            "Epoch 107/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7117\n",
            "Epoch 108/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1901 - binary_accuracy: 0.7236\n",
            "Epoch 109/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.7236\n",
            "Epoch 110/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 0.7192\n",
            "Epoch 111/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7177\n",
            "Epoch 112/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1911 - binary_accuracy: 0.7162\n",
            "Epoch 113/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1914 - binary_accuracy: 0.7221\n",
            "Epoch 114/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7103\n",
            "Epoch 115/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1914 - binary_accuracy: 0.7132\n",
            "Epoch 116/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1901 - binary_accuracy: 0.7088\n",
            "Epoch 117/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7132\n",
            "Epoch 118/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7221\n",
            "Epoch 119/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1911 - binary_accuracy: 0.7221\n",
            "Epoch 120/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7221\n",
            "Epoch 121/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7177\n",
            "Epoch 122/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7177\n",
            "Epoch 123/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7221\n",
            "Epoch 124/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7162\n",
            "Epoch 125/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1905 - binary_accuracy: 0.7132\n",
            "Epoch 126/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7162\n",
            "Epoch 127/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1922 - binary_accuracy: 0.7132\n",
            "Epoch 128/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1903 - binary_accuracy: 0.7177\n",
            "Epoch 129/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7177\n",
            "Epoch 130/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7177\n",
            "Epoch 131/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1901 - binary_accuracy: 0.7192\n",
            "Epoch 132/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7207\n",
            "Epoch 133/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1903 - binary_accuracy: 0.7132\n",
            "Epoch 134/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7162\n",
            "Epoch 135/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1907 - binary_accuracy: 0.7117\n",
            "Epoch 136/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7162\n",
            "Epoch 137/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7132\n",
            "Epoch 138/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1912 - binary_accuracy: 0.7207\n",
            "Epoch 139/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1897 - binary_accuracy: 0.7207\n",
            "Epoch 140/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 141/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1918 - binary_accuracy: 0.7192\n",
            "Epoch 142/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7192\n",
            "Epoch 143/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 0.7251\n",
            "Epoch 144/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7147\n",
            "Epoch 145/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7207\n",
            "Epoch 146/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1898 - binary_accuracy: 0.7192\n",
            "Epoch 147/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7221\n",
            "Epoch 148/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7207\n",
            "Epoch 149/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1887 - binary_accuracy: 0.7221\n",
            "Epoch 150/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1903 - binary_accuracy: 0.7192\n",
            "Epoch 151/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7207\n",
            "Epoch 152/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7162\n",
            "Epoch 153/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1904 - binary_accuracy: 0.7162\n",
            "Epoch 154/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7177\n",
            "Epoch 155/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7192\n",
            "Epoch 156/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7117\n",
            "Epoch 157/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1911 - binary_accuracy: 0.7207\n",
            "Epoch 158/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1914 - binary_accuracy: 0.7207\n",
            "Epoch 159/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7236\n",
            "Epoch 160/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1926 - binary_accuracy: 0.7236\n",
            "Epoch 161/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7147\n",
            "Epoch 162/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7177\n",
            "Epoch 163/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1922 - binary_accuracy: 0.7177\n",
            "Epoch 164/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1901 - binary_accuracy: 0.7221\n",
            "Epoch 165/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7192\n",
            "Epoch 166/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1895 - binary_accuracy: 0.7177\n",
            "Epoch 167/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1904 - binary_accuracy: 0.7147\n",
            "Epoch 168/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1937 - binary_accuracy: 0.7147\n",
            "Epoch 169/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.7147\n",
            "Epoch 170/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1921 - binary_accuracy: 0.7177\n",
            "Epoch 171/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7162\n",
            "Epoch 172/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7177\n",
            "Epoch 173/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1893 - binary_accuracy: 0.7236\n",
            "Epoch 174/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1885 - binary_accuracy: 0.7117\n",
            "Epoch 175/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7162\n",
            "Epoch 176/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7132\n",
            "Epoch 177/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7177\n",
            "Epoch 178/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1899 - binary_accuracy: 0.7177\n",
            "Epoch 179/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7236\n",
            "Epoch 180/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1911 - binary_accuracy: 0.7192\n",
            "Epoch 181/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1916 - binary_accuracy: 0.7177\n",
            "Epoch 182/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1913 - binary_accuracy: 0.7147\n",
            "Epoch 183/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7177\n",
            "Epoch 184/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - binary_accuracy: 0.7073\n",
            "Epoch 185/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7058\n",
            "Epoch 186/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1889 - binary_accuracy: 0.7221\n",
            "Epoch 187/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1908 - binary_accuracy: 0.7192\n",
            "Epoch 188/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1895 - binary_accuracy: 0.7147\n",
            "Epoch 189/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1910 - binary_accuracy: 0.7221\n",
            "Epoch 190/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1881 - binary_accuracy: 0.7162\n",
            "Epoch 191/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7177\n",
            "Epoch 192/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7147\n",
            "Epoch 193/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1882 - binary_accuracy: 0.7162\n",
            "Epoch 194/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.7221\n",
            "Epoch 195/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7132\n",
            "Epoch 196/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1903 - binary_accuracy: 0.7221\n",
            "Epoch 197/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1913 - binary_accuracy: 0.7177\n",
            "Epoch 198/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7221\n",
            "Epoch 199/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7177\n",
            "Epoch 200/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1889 - binary_accuracy: 0.7236\n",
            "Epoch 201/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7162\n",
            "Epoch 202/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1895 - binary_accuracy: 0.7236\n",
            "Epoch 203/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7162\n",
            "Epoch 204/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1913 - binary_accuracy: 0.7132\n",
            "Epoch 205/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1892 - binary_accuracy: 0.7192\n",
            "Epoch 206/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1891 - binary_accuracy: 0.7192\n",
            "Epoch 207/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 208/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7192\n",
            "Epoch 209/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1890 - binary_accuracy: 0.7236\n",
            "Epoch 210/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7221\n",
            "Epoch 211/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1886 - binary_accuracy: 0.7251\n",
            "Epoch 212/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7177\n",
            "Epoch 213/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1910 - binary_accuracy: 0.7177\n",
            "Epoch 214/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1896 - binary_accuracy: 0.7147\n",
            "Epoch 215/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1893 - binary_accuracy: 0.7162\n",
            "Epoch 216/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.7251\n",
            "Epoch 217/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7117\n",
            "Epoch 218/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1892 - binary_accuracy: 0.7132\n",
            "Epoch 219/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7192\n",
            "Epoch 220/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1913 - binary_accuracy: 0.7132\n",
            "Epoch 221/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7132\n",
            "Epoch 222/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1895 - binary_accuracy: 0.7192\n",
            "Epoch 223/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1919 - binary_accuracy: 0.7162\n",
            "Epoch 224/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1899 - binary_accuracy: 0.7132\n",
            "Epoch 225/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7162\n",
            "Epoch 226/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1904 - binary_accuracy: 0.7221\n",
            "Epoch 227/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7147\n",
            "Epoch 228/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1900 - binary_accuracy: 0.7236\n",
            "Epoch 229/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1888 - binary_accuracy: 0.7132\n",
            "Epoch 230/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1903 - binary_accuracy: 0.7207\n",
            "Epoch 231/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1892 - binary_accuracy: 0.7177\n",
            "Epoch 232/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 233/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7236\n",
            "Epoch 234/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1907 - binary_accuracy: 0.7177\n",
            "Epoch 235/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 236/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1890 - binary_accuracy: 0.7162\n",
            "Epoch 237/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1913 - binary_accuracy: 0.7147\n",
            "Epoch 238/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7147\n",
            "Epoch 239/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1899 - binary_accuracy: 0.7132\n",
            "Epoch 240/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1901 - binary_accuracy: 0.7177\n",
            "Epoch 241/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1888 - binary_accuracy: 0.7266\n",
            "Epoch 242/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1887 - binary_accuracy: 0.7221\n",
            "Epoch 243/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1902 - binary_accuracy: 0.7207\n",
            "Epoch 244/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1888 - binary_accuracy: 0.7177\n",
            "Epoch 245/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1897 - binary_accuracy: 0.7251\n",
            "Epoch 246/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1895 - binary_accuracy: 0.7177\n",
            "Epoch 247/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1890 - binary_accuracy: 0.7236\n",
            "Epoch 248/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1914 - binary_accuracy: 0.7147\n",
            "Epoch 249/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 250/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1904 - binary_accuracy: 0.7132\n",
            "Epoch 251/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7236\n",
            "Epoch 252/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1890 - binary_accuracy: 0.7177\n",
            "Epoch 253/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1894 - binary_accuracy: 0.7192\n",
            "Epoch 254/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7207\n",
            "Epoch 255/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7221\n",
            "Epoch 256/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7221\n",
            "Epoch 257/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7162\n",
            "Epoch 258/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7132\n",
            "Epoch 259/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1875 - binary_accuracy: 0.7221\n",
            "Epoch 260/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1893 - binary_accuracy: 0.7132\n",
            "Epoch 261/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7177\n",
            "Epoch 262/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1905 - binary_accuracy: 0.7132\n",
            "Epoch 263/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1893 - binary_accuracy: 0.7207\n",
            "Epoch 264/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1878 - binary_accuracy: 0.7281\n",
            "Epoch 265/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 266/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1891 - binary_accuracy: 0.7177\n",
            "Epoch 267/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1895 - binary_accuracy: 0.7251\n",
            "Epoch 268/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1897 - binary_accuracy: 0.7192\n",
            "Epoch 269/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7192\n",
            "Epoch 270/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7162\n",
            "Epoch 271/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1890 - binary_accuracy: 0.7162\n",
            "Epoch 272/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1901 - binary_accuracy: 0.7251\n",
            "Epoch 273/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7207\n",
            "Epoch 274/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1890 - binary_accuracy: 0.7177\n",
            "Epoch 275/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1895 - binary_accuracy: 0.7192\n",
            "Epoch 276/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1892 - binary_accuracy: 0.7132\n",
            "Epoch 277/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1887 - binary_accuracy: 0.7117\n",
            "Epoch 278/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1898 - binary_accuracy: 0.7207\n",
            "Epoch 279/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.7221\n",
            "Epoch 280/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7132\n",
            "Epoch 281/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7162\n",
            "Epoch 282/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1895 - binary_accuracy: 0.7162\n",
            "Epoch 283/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7236\n",
            "Epoch 284/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1896 - binary_accuracy: 0.7236\n",
            "Epoch 285/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.7073\n",
            "Epoch 286/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7236\n",
            "Epoch 287/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1891 - binary_accuracy: 0.7117\n",
            "Epoch 288/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7207\n",
            "Epoch 289/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1886 - binary_accuracy: 0.7192\n",
            "Epoch 290/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1893 - binary_accuracy: 0.7207\n",
            "Epoch 291/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1886 - binary_accuracy: 0.7147\n",
            "Epoch 292/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1912 - binary_accuracy: 0.7177\n",
            "Epoch 293/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1894 - binary_accuracy: 0.7117\n",
            "Epoch 294/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1880 - binary_accuracy: 0.7192\n",
            "Epoch 295/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.7207\n",
            "Epoch 296/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1882 - binary_accuracy: 0.7177\n",
            "Epoch 297/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - binary_accuracy: 0.7132\n",
            "Epoch 298/300\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1895 - binary_accuracy: 0.7192\n",
            "Epoch 299/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1897 - binary_accuracy: 0.7162\n",
            "Epoch 300/300\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb7e9c95b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymp9aozr2Shq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}